{"cells":[{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2484,"status":"ok","timestamp":1664779678534,"user":{"displayName":"Ashley Ho","userId":"17045796355417485048"},"user_tz":-480},"id":"3RcZ27W4T-c9","outputId":"1d1bb1f5-a5cd-4978-938a-c2cc6c0f4804"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package names to /Users/eltontay/nltk_data...\n","[nltk_data]   Package names is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package vader_lexicon to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n","[nltk_data] Downloading package punkt to /Users/eltontay/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","\n","nltk.download([\n","    \"names\",\n","    \"stopwords\",\n","    \"averaged_perceptron_tagger\",\n","    \"vader_lexicon\",\n","    \"punkt\",\n","    ])"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1712,"status":"ok","timestamp":1664779680238,"user":{"displayName":"Ashley Ho","userId":"17045796355417485048"},"user_tz":-480},"id":"cvyNoXiquVGx","outputId":"f1b1ad36-446b-4e30-a7a9-b95a16857c9d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package stopwords to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     /Users/eltontay/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","import json\n","\n","import nltk\n","nltk.download('omw-1.4')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","import string\n","import re"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":1124,"status":"ok","timestamp":1664780743584,"user":{"displayName":"Ashley Ho","userId":"17045796355417485048"},"user_tz":-480},"id":"HXuzdaekt850","outputId":"684aa906-f3c3-419e-8ffd-f22590d6290c"},"outputs":[{"name":"stdout","output_type":"stream","text":["world shape  (33728, 2)\n","politics shape  (6176, 2)\n","coronavirus shape  (5184, 2)\n","aapl shape  (8048, 2)\n","meta shape  (9528, 2)\n","tsla shape  (6208, 2)\n","           Date                                              Title\n","0  Aug 31, 2022  Equities close lower as rise in yields oversha...\n","1  Aug 31, 2022  Wall St ends red, Treasury yields climb on dou...\n","2  Aug 31, 2022                     Tesla Falls Following Mixed Q3\n","3  Aug 31, 2022            2 Oversold Tech Gems With Strong Upside\n","4  Aug 31, 2022  Chart Of The Day: AMD's Decline Could Be Far F...\n"]}],"source":["df_world= pd.read_csv('../Data/News/Global/world_news.csv')\n","df_politics= pd.read_csv('../Data/News/Global/politics_news.csv')\n","df_coronavirus= pd.read_csv('../Data/News/Global/coronavirus_news.csv')\n","df_aapl= pd.read_csv('../Data/News/Stock/aapl_news.csv')\n","df_meta= pd.read_csv('../Data/News/Stock/meta_news.csv')\n","df_tsla= pd.read_csv('../Data/News/Stock/tsla_news.csv')\n","print('world shape ', df_world.shape)\n","print('politics shape ',df_politics.shape)\n","print('coronavirus shape ',df_coronavirus.shape)\n","print('aapl shape ',df_aapl.shape)\n","print('meta shape ', df_meta.shape)\n","print('tsla shape ', df_tsla.shape)\n","print(df_aapl.head())"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"0g8OyI4Y35Ny"},"outputs":[],"source":["def remove_irrelevant_content(text):\n","    headline_only_string = \"This headline-only article is meant to show you why a stock is moving, the most difficult aspect of stock trading\"\n","\n","    if headline_only_string in text:\n","        return \"\"\n","    else:\n","        return text\n","\n","def remove_punctuation(text):\n","    text = re.sub(r'[^\\w\\s]', '', text)\n","    return text\n","\n","def lowercase(text):\n","    return text.lower()\n","\n","def remove_stopwords(text):\n","    stopwords = nltk.corpus.stopwords.words('english')\n","    text = ' '.join([word for word in text.split() if word not in stopwords])\n","    return text\n","\n","def remove_special_character(text):\n","    text = text.replace('\\n', ' ') \n","    return text\n","\n","def lemmatize(text):\n","    lem = WordNetLemmatizer()\n","    corpus = [[lem.lemmatize(x, pos = 'v') for x in x] for x in text]\n","    return corpus\n","\n","def preprocess_text(text):\n","    text = remove_irrelevant_content(text)\n","    text = remove_punctuation(text)\n","    text = lowercase(text)\n","    # text = remove_stopwords(text)\n","    text = remove_special_character(text)\n","    # text = lemmatize(text)\n","    return text"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["sia = SentimentIntensityAnalyzer()\n","\n","def vader_process(df) : \n","    df['Date'] = pd.to_datetime(df['Date'])\n","    df['Processed Title'] = df['Title'].apply(lambda x: preprocess_text(x))\n","    # df['Processed Text'] = df['Text'].apply(lambda x: preprocess_text(x))\n","    df['Sentiment Title'] = df['Processed Title'].apply(lambda x: sia.polarity_scores(x))\n","    # df['Sentiment Text'] = df['Processed Text'].apply(lambda x: sia.polarity_scores(x))\n","    # df['Positive Title'] = df['Sentiment Title'].apply(lambda x: x[\"compound\"] > 0)\n","    # df['Positive Text'] = df['Sentiment Text'].apply(lambda x: x[\"compound\"] > 0)\n","    return df"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["def sentiment_aggregator(df, title = True, type=\"mean\"):\n","    \"\"\"\n","    Aggregates sentiments on a per day basis.\n","\n","    Parameters\n","    ----------\n","    df: DataFrame\n","        Dataset generated after sentiment analysis.\n","    title: boolean\n","        To indicate if the news title or news body text is used to generate the aggregated sentiment. \n","        Default is True (ie. News title is used for aggregated sentiment)\n","    type: Str {\"mean\", \"abs_max\"}\n","        To indicate method of calculation.\n","        \"mean\": Group by Date and takes mean of \"Compound\"\n","        \"abs_max\": Calculates the absolute max of \"Positive\" and \"Negative\" column. Then group by Date and takes mean of this new column\n","\n","    Returns\n","    -------\n","    Output : Series\n","        Contains aggregated sentiment for each day\n","    \"\"\"\n","   \n","    target = \"Sentiment Title\"\n","    #  if title else \"Sentiment Text\"\n","    \n","    df[target] = df[target].str.replace('\\'','\\\"')\n","    df[target] = df[target].apply(lambda x: json.loads(x))\n","\n","    df['Negative'] = df[target].apply(lambda x: x.get('neg'))\n","    df['Neutral'] = df[target].apply(lambda x: x.get('neu'))\n","    df['Positive'] = df[target].apply(lambda x: x.get('pos'))\n","    df['Compound'] = df[target].apply(lambda x: x.get('compound'))\n","\n","    if type == \"mean\":\n","        return df.groupby('Date')['Compound'].aggregate('mean')\n","\n","    elif type == \"abs_max\":\n","        df['Negative'] = df[target].apply(lambda x: -x.get('neg'))\n","        df['Sentiment'] = df.apply(lambda x: max(x['Negative'], x['Positive'], key=abs), axis=1)\n","\n","        return df.groupby('Date')['Sentiment'].aggregate('mean')\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["def vader_all():\n","    df_world= pd.read_csv('../Data/News/Global/world_news.csv')\n","    df_politics= pd.read_csv('../Data/News/Global/politics_news.csv')\n","    df_coronavirus= pd.read_csv('../Data/News/Global/coronavirus_news.csv')\n","    df_aapl= pd.read_csv('../Data/News/Stock/aapl_news.csv')\n","    df_meta= pd.read_csv('../Data/News/Stock/meta_news.csv')\n","    df_tsla= pd.read_csv('../Data/News/Stock/tsla_news.csv')\n","    \n","    df_aapl = vader_process(df_aapl)\n","    df_meta = vader_process(df_meta)\n","    df_tsla = vader_process(df_tsla)\n","    df_world = vader_process(df_world)\n","    df_politics = vader_process(df_politics)\n","    df_coronavirus = vader_process(df_coronavirus)\n","\n","    df_aapl.to_csv('../Data-Processed/News/Stock/aapl_vader.csv',index=False)\n","    df_meta.to_csv('../Data-Processed/News/Stock/meta_vader.csv',index=False)\n","    df_tsla.to_csv('../Data-Processed/News/Stock/tsla_vader.csv',index=False)\n","    df_world.to_csv('../Data-Processed/News/Global/world_vader.csv',index=False)\n","    df_politics.to_csv('../Data-Processed/News/Global/politics_vader.csv',index=False)\n","    df_coronavirus.to_csv('../Data-Processed/News/Global/coronavirus_vader.csv',index=False)\n","    \n","\n","def aggregate_sentiment_all(title, type):\n","    df_world_vader= pd.read_csv('../Data-Processed/News/Global/world_vader.csv')\n","    df_politics_vader= pd.read_csv('../Data-Processed/News/Global/politics_vader.csv')\n","    df_coronavirus_vader= pd.read_csv('../Data-Processed/News/Global/coronavirus_vader.csv')\n","    df_aapl_vader= pd.read_csv('../Data-Processed/News/Stock/aapl_vader.csv')\n","    df_meta_vader= pd.read_csv('../Data-Processed/News/Stock/meta_vader.csv')\n","    df_tsla_vader= pd.read_csv('../Data-Processed/News/Stock/tsla_vader.csv')\n","\n","    aggregated_sentiment_aapl = sentiment_aggregator(df_aapl_vader, title=title, type=type)\n","    aggregated_sentiment_meta = sentiment_aggregator(df_meta_vader, title=title, type=type)\n","    aggregated_sentiment_tsla = sentiment_aggregator(df_tsla_vader, title=title, type=type)\n","    aggregated_sentiment_world = sentiment_aggregator(df_world_vader, title=title, type=type)\n","    aggregated_sentiment_politics = sentiment_aggregator(df_politics_vader, title=title, type=type)\n","    aggregated_sentiment_coronavirus = sentiment_aggregator(df_coronavirus_vader, title=title, type=type)\n","\n","    lst = [aggregated_sentiment_aapl, aggregated_sentiment_meta, aggregated_sentiment_tsla, aggregated_sentiment_world, aggregated_sentiment_politics, aggregated_sentiment_coronavirus]\n","    keys = [\"AAPL\", \"META\", \"TSLA\", \"World\", \"Politics\", \"Coronavirus\"]\n","    \n","    return pd.concat(lst, keys=keys, axis=1)\n"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["vader_all()"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[],"source":["#vader_all()\n","df_all = aggregate_sentiment_all(title=True, type=\"abs_max\")\n","df_all = df_all.sort_values(by=\"Date\")\n","df_all.to_csv('../Data-Processed/all_vader.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
