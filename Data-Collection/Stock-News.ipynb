{"cells":[{"cell_type":"markdown","metadata":{},"source":["Meta, Apple and Tesla stock news are extracted using beautifulsoup"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1651,"status":"ok","timestamp":1665490627375,"user":{"displayName":"Hui Yi Yap","userId":"03311066239564655489"},"user_tz":-480},"id":"D9lKfRn9QdU7","outputId":"5e808a5f-0049-4870-acb4-da9869587c4f"},"outputs":[],"source":["import pandas as pd\n","import sys\n","import requests\n","from bs4 import BeautifulSoup"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["limit = 3 # setting to 3 articles limit per page\n","\n","def getDate(url):\n","    page = requests.get(url)\n","    soup = BeautifulSoup(page.content, 'html.parser')\n","    dates = soup.find_all(class_ = \"date\") \n","    dateArray=[]\n","    count = 1\n","    for date in dates :\n","        dateArray.append(date.get_text().split()[1:])\n","        if count >= limit :\n","            break\n","        count += 1    \n","    return dateArray\n","\n","# tweak start and end for faster compile\n","def getStartEnd(url,startnum,endnum):\n","    try :\n","        check = True\n","        start = getDate(\"{}{}\".format(url,startnum))\n","        while check :\n","            if (start[2][0] == 'Aug' and start[2][2] == '2022') :\n","                check = False\n","                break\n","            startnum += 1\n","            start = getDate(\"{}{}\".format(url,startnum))\n","            print(start)\n","        print(startnum)\n","        check = True\n","        end = getDate(\"{}{}\".format(url,endnum))\n","        while check :\n","            if end[2][0] == 'Jan' and end[2][2] == '2018' :\n","                check = False\n","                break\n","            endnum += 1\n","            end = getDate(\"{}{}\".format(url,endnum))    \n","            print(end)\n","        print(endnum)\n","        return (startnum,endnum)\n","    except : \n","        print(\"error\")\n","\n","def getArticles(url,startnum,endnum):\n","    df = pd.DataFrame(columns=['Date','Title','Text'])\n","    start,end = getStartEnd(url,startnum,endnum)\n","    while start <= end :\n","        page = requests.get(\"{}{}\".format(url,start))\n","        soup = BeautifulSoup(page.content, 'html.parser')\n","        dates = soup.find_all(class_=\"date\")\n","        titles = soup.find_all(class_ = \"title\") \n","        texts = soup.find_all(\"p\")\n","        nTexts = []\n","        textCount = 0\n","        for t in texts :\n","            if t.text[:2] == \"By\":\n","                nTexts.append(t.text)\n","                textCount += 1\n","            if textCount == limit :\n","                break\n","        for i in range(textCount) :\n","            df_new = pd.DataFrame({\"Date\" : dates[i].text[3:], \"Title\" : titles[i].text, \"Text\" : nTexts[i]},index=[1])\n","            df = pd.concat([df,df_new],ignore_index=True)\n","        print(start, end, \"[Page {}/{}]\".format(start, end))\n","        start += 1\n","    return df"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["36\n","811\n","36 811 [Page 36/811]\n","37 811 [Page 37/811]\n","38 811 [Page 38/811]\n","39 811 [Page 39/811]\n","40 811 [Page 40/811]\n","41 811 [Page 41/811]\n","42 811 [Page 42/811]\n","43 811 [Page 43/811]\n","44 811 [Page 44/811]\n","45 811 [Page 45/811]\n","46 811 [Page 46/811]\n","47 811 [Page 47/811]\n","48 811 [Page 48/811]\n","49 811 [Page 49/811]\n","50 811 [Page 50/811]\n","51 811 [Page 51/811]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_tsla \u001b[39m=\u001b[39m getArticles(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.investing.com/equities/tesla-motors-news/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m36\u001b[39;49m,\u001b[39m811\u001b[39;49m)\n","Cell \u001b[0;32mIn [11], line 48\u001b[0m, in \u001b[0;36mgetArticles\u001b[0;34m(url, startnum, endnum)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mwhile\u001b[39;00m start \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m end :\n\u001b[1;32m     47\u001b[0m     page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url,start))\n\u001b[0;32m---> 48\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(page\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     49\u001b[0m     dates \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     titles \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m) \n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[1;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[1;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/html/parser.py:170\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[39mif\u001b[39;00m startswith(\u001b[39m'\u001b[39m\u001b[39m<\u001b[39m\u001b[39m'\u001b[39m, i):\n\u001b[1;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m starttagopen\u001b[39m.\u001b[39mmatch(rawdata, i): \u001b[39m# < + letter\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_starttag(i)\n\u001b[1;32m    171\u001b[0m     \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m</\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m    172\u001b[0m         k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_endtag(i)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/html/parser.py:344\u001b[0m, in \u001b[0;36mHTMLParser.parse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_startendtag(tag, attrs)\n\u001b[1;32m    343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 344\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_starttag(tag, attrs)\n\u001b[1;32m    345\u001b[0m     \u001b[39mif\u001b[39;00m tag \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mCDATA_CONTENT_ELEMENTS:\n\u001b[1;32m    346\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_cdata_mode(tag)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:154\u001b[0m, in \u001b[0;36mBeautifulSoupHTMLParser.handle_starttag\u001b[0;34m(self, name, attrs, handle_empty_element)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39m#print(\"START\", name)\u001b[39;00m\n\u001b[1;32m    153\u001b[0m sourceline, sourcepos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetpos()\n\u001b[0;32m--> 154\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msoup\u001b[39m.\u001b[39;49mhandle_starttag(\n\u001b[1;32m    155\u001b[0m     name, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, attr_dict, sourceline\u001b[39m=\u001b[39;49msourceline,\n\u001b[1;32m    156\u001b[0m     sourcepos\u001b[39m=\u001b[39;49msourcepos\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mand\u001b[39;00m tag\u001b[39m.\u001b[39mis_empty_element \u001b[39mand\u001b[39;00m handle_empty_element:\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Unlike other parsers, html.parser doesn't send separate end tag\u001b[39;00m\n\u001b[1;32m    160\u001b[0m     \u001b[39m# events for empty-element tags. (It's handled in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[39m# don't want handle_endtag() to cross off any previous end\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39m# events for tags of this name.\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_endtag(name, check_already_closed\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:723\u001b[0m, in \u001b[0;36mBeautifulSoup.handle_starttag\u001b[0;34m(self, name, namespace, nsprefix, attrs, sourceline, sourcepos, namespaces)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtagStack) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    717\u001b[0m     \u001b[39mand\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39mtext\n\u001b[1;32m    718\u001b[0m          \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparse_only\u001b[39m.\u001b[39msearch_tag(name, attrs))):\n\u001b[1;32m    719\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    721\u001b[0m tag \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39melement_classes\u001b[39m.\u001b[39mget(Tag, Tag)(\n\u001b[1;32m    722\u001b[0m     \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder, name, namespace, nsprefix, attrs,\n\u001b[0;32m--> 723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrentTag, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_most_recent_element,\n\u001b[1;32m    724\u001b[0m     sourceline\u001b[39m=\u001b[39msourceline, sourcepos\u001b[39m=\u001b[39msourcepos,\n\u001b[1;32m    725\u001b[0m     namespaces\u001b[39m=\u001b[39mnamespaces\n\u001b[1;32m    726\u001b[0m )\n\u001b[1;32m    727\u001b[0m \u001b[39mif\u001b[39;00m tag \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     \u001b[39mreturn\u001b[39;00m tag\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df_tsla = getArticles(\"https://www.investing.com/equities/tesla-motors-news/\",36,811)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["30\n","[['Mar', '23,', '2018'], ['Mar', '23,', '2018'], ['Mar', '23,', '2018']]\n","[['Mar', '22,', '2018'], ['Mar', '22,', '2018'], ['Mar', '22,', '2018']]\n","[['Mar', '21,', '2018'], ['Mar', '21,', '2018'], ['Mar', '21,', '2018']]\n","[['Mar', '20,', '2018'], ['Mar', '20,', '2018'], ['Mar', '20,', '2018']]\n","[['Mar', '19,', '2018'], ['Mar', '19,', '2018'], ['Mar', '19,', '2018']]\n","[['Mar', '18,', '2018'], ['Mar', '18,', '2018'], ['Mar', '17,', '2018']]\n","[['Mar', '15,', '2018'], ['Mar', '15,', '2018'], ['Mar', '15,', '2018']]\n","[['Mar', '14,', '2018'], ['Mar', '14,', '2018'], ['Mar', '14,', '2018']]\n","[['Mar', '13,', '2018'], ['Mar', '13,', '2018'], ['Mar', '12,', '2018']]\n","[['Mar', '12,', '2018'], ['Mar', '12,', '2018'], ['Mar', '09,', '2018']]\n","[['Mar', '08,', '2018'], ['Mar', '08,', '2018'], ['Mar', '08,', '2018']]\n","[['Mar', '06,', '2018'], ['Mar', '05,', '2018'], ['Mar', '05,', '2018']]\n","[['Mar', '02,', '2018'], ['Mar', '02,', '2018'], ['Mar', '02,', '2018']]\n","[['Feb', '28,', '2018'], ['Feb', '28,', '2018'], ['Feb', '28,', '2018']]\n","[['Feb', '27,', '2018'], ['Feb', '27,', '2018'], ['Feb', '27,', '2018']]\n","[['Feb', '26,', '2018'], ['Feb', '26,', '2018'], ['Feb', '26,', '2018']]\n","[['Feb', '25,', '2018'], ['Feb', '25,', '2018'], ['Feb', '24,', '2018']]\n","[['Feb', '22,', '2018'], ['Feb', '22,', '2018'], ['Feb', '22,', '2018']]\n","[['Feb', '21,', '2018'], ['Feb', '21,', '2018'], ['Feb', '21,', '2018']]\n","[['Feb', '17,', '2018'], ['Feb', '16,', '2018'], ['Feb', '16,', '2018']]\n","[['Feb', '15,', '2018'], ['Feb', '15,', '2018'], ['Feb', '15,', '2018']]\n","[['Feb', '14,', '2018'], ['Feb', '14,', '2018'], ['Feb', '14,', '2018']]\n","[['Feb', '13,', '2018'], ['Feb', '13,', '2018'], ['Feb', '13,', '2018']]\n","[['Feb', '12,', '2018'], ['Feb', '12,', '2018'], ['Feb', '12,', '2018']]\n","[['Feb', '08,', '2018'], ['Feb', '08,', '2018'], ['Feb', '07,', '2018']]\n","[['Feb', '07,', '2018'], ['Feb', '07,', '2018'], ['Feb', '07,', '2018']]\n","[['Feb', '06,', '2018'], ['Feb', '06,', '2018'], ['Feb', '06,', '2018']]\n","[['Feb', '06,', '2018'], ['Feb', '05,', '2018'], ['Feb', '05,', '2018']]\n","[['Feb', '05,', '2018'], ['Feb', '05,', '2018'], ['Feb', '05,', '2018']]\n","[['Feb', '04,', '2018'], ['Feb', '04,', '2018'], ['Feb', '04,', '2018']]\n","[['Feb', '02,', '2018'], ['Feb', '02,', '2018'], ['Feb', '02,', '2018']]\n","[['Feb', '02,', '2018'], ['Feb', '02,', '2018'], ['Feb', '02,', '2018']]\n","[['Feb', '01,', '2018'], ['Feb', '01,', '2018'], ['Feb', '01,', '2018']]\n","[['Jan', '31,', '2018'], ['Jan', '31,', '2018'], ['Jan', '31,', '2018']]\n","1034\n","30 1034 [Page 30/1034]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_aapl \u001b[39m=\u001b[39m getArticles(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.investing.com/equities/apple-computer-inc-news/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m30\u001b[39;49m,\u001b[39m1000\u001b[39;49m)\n","Cell \u001b[0;32mIn [11], line 48\u001b[0m, in \u001b[0;36mgetArticles\u001b[0;34m(url, startnum, endnum)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mwhile\u001b[39;00m start \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m end :\n\u001b[1;32m     47\u001b[0m     page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url,start))\n\u001b[0;32m---> 48\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(page\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     49\u001b[0m     dates \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     titles \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m) \n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:333\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n\u001b[1;32m    332\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed()\n\u001b[1;32m    334\u001b[0m     success \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    335\u001b[0m     \u001b[39mbreak\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:451\u001b[0m, in \u001b[0;36mBeautifulSoup._feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39m# Convert the document to Unicode.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 451\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbuilder\u001b[39m.\u001b[39;49mfeed(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    452\u001b[0m \u001b[39m# Close out any unfinished strings and close all the open tags.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendData()\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:399\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.feed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    397\u001b[0m parser\u001b[39m.\u001b[39msoup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msoup\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     parser\u001b[39m.\u001b[39;49mfeed(markup)\n\u001b[1;32m    400\u001b[0m     parser\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    401\u001b[0m \u001b[39mexcept\u001b[39;00m HTMLParseError \u001b[39mas\u001b[39;00m e:\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/html/parser.py:110\u001b[0m, in \u001b[0;36mHTMLParser.feed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Feed data to the parser.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mCall this as often as you want, with as little or as much text\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[39mas you want (may include '\\n').\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata \u001b[39m+\u001b[39m data\n\u001b[0;32m--> 110\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgoahead(\u001b[39m0\u001b[39;49m)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/html/parser.py:198\u001b[0m, in \u001b[0;36mHTMLParser.goahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_data(rawdata[i:k])\n\u001b[0;32m--> 198\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdatepos(i, k)\n\u001b[1;32m    199\u001b[0m \u001b[39melif\u001b[39;00m startswith(\u001b[39m\"\u001b[39m\u001b[39m&#\u001b[39m\u001b[39m\"\u001b[39m, i):\n\u001b[1;32m    200\u001b[0m     match \u001b[39m=\u001b[39m charref\u001b[39m.\u001b[39mmatch(rawdata, i)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/_markupbase.py:52\u001b[0m, in \u001b[0;36mParserBase.updatepos\u001b[0;34m(self, i, j)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m j\n\u001b[1;32m     51\u001b[0m rawdata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrawdata\n\u001b[0;32m---> 52\u001b[0m nlines \u001b[39m=\u001b[39m rawdata\u001b[39m.\u001b[39;49mcount(\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, i, j)\n\u001b[1;32m     53\u001b[0m \u001b[39mif\u001b[39;00m nlines:\n\u001b[1;32m     54\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineno \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineno \u001b[39m+\u001b[39m nlines\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df_aapl = getArticles(\"https://www.investing.com/equities/apple-computer-inc-news/\",30,1034) "]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["20\n","[['Feb', '14,', '2018'], ['Feb', '13,', '2018'], ['Feb', '13,', '2018']]\n","[['Feb', '13,', '2018'], ['Feb', '12,', '2018'], ['Feb', '12,', '2018']]\n","[['Feb', '10,', '2018'], ['Feb', '09,', '2018'], ['Feb', '09,', '2018']]\n","[['Feb', '09,', '2018'], ['Feb', '09,', '2018'], ['Feb', '09,', '2018']]\n","[['Feb', '08,', '2018'], ['Feb', '08,', '2018'], ['Feb', '08,', '2018']]\n","[['Feb', '06,', '2018'], ['Feb', '06,', '2018'], ['Feb', '06,', '2018']]\n","[['Feb', '05,', '2018'], ['Feb', '05,', '2018'], ['Feb', '05,', '2018']]\n","[['Feb', '03,', '2018'], ['Feb', '02,', '2018'], ['Feb', '02,', '2018']]\n","[['Feb', '02,', '2018'], ['Feb', '01,', '2018'], ['Feb', '01,', '2018']]\n","[['Feb', '01,', '2018'], ['Feb', '01,', '2018'], ['Feb', '01,', '2018']]\n","[['Jan', '31,', '2018'], ['Jan', '31,', '2018'], ['Jan', '31,', '2018']]\n","1211\n","20 1211 [Page 20/1211]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn [21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_meta \u001b[39m=\u001b[39m getArticles(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://www.investing.com/equities/facebook-inc-news/\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m20\u001b[39;49m,\u001b[39m1200\u001b[39;49m)\n","Cell \u001b[0;32mIn [11], line 48\u001b[0m, in \u001b[0;36mgetArticles\u001b[0;34m(url, startnum, endnum)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mwhile\u001b[39;00m start \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m end :\n\u001b[1;32m     47\u001b[0m     page \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(url,start))\n\u001b[0;32m---> 48\u001b[0m     soup \u001b[39m=\u001b[39m BeautifulSoup(page\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     49\u001b[0m     dates \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     titles \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(class_ \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m) \n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/__init__.py:326\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m rejections \u001b[39m=\u001b[39m []\n\u001b[1;32m    325\u001b[0m success \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m \u001b[39mfor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarkup, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moriginal_encoding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeclared_html_encoding,\n\u001b[1;32m    327\u001b[0m  \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontains_replacement_characters) \u001b[39min\u001b[39;00m (\n\u001b[1;32m    328\u001b[0m      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39mprepare_markup(\n\u001b[1;32m    329\u001b[0m          markup, from_encoding, exclude_encodings\u001b[39m=\u001b[39mexclude_encodings)):\n\u001b[1;32m    330\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    331\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39minitialize_soup(\u001b[39mself\u001b[39m)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/builder/_htmlparser.py:380\u001b[0m, in \u001b[0;36mHTMLParserTreeBuilder.prepare_markup\u001b[0;34m(self, markup, user_specified_encoding, document_declared_encoding, exclude_encodings)\u001b[0m\n\u001b[1;32m    377\u001b[0m user_encodings \u001b[39m=\u001b[39m [document_declared_encoding]\n\u001b[1;32m    379\u001b[0m try_encodings \u001b[39m=\u001b[39m [user_specified_encoding, document_declared_encoding]\n\u001b[0;32m--> 380\u001b[0m dammit \u001b[39m=\u001b[39m UnicodeDammit(\n\u001b[1;32m    381\u001b[0m     markup,\n\u001b[1;32m    382\u001b[0m     known_definite_encodings\u001b[39m=\u001b[39;49mknown_definite_encodings,\n\u001b[1;32m    383\u001b[0m     user_encodings\u001b[39m=\u001b[39;49muser_encodings,\n\u001b[1;32m    384\u001b[0m     is_html\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    385\u001b[0m     exclude_encodings\u001b[39m=\u001b[39;49mexclude_encodings\n\u001b[1;32m    386\u001b[0m )\n\u001b[1;32m    387\u001b[0m \u001b[39myield\u001b[39;00m (dammit\u001b[39m.\u001b[39mmarkup, dammit\u001b[39m.\u001b[39moriginal_encoding,\n\u001b[1;32m    388\u001b[0m        dammit\u001b[39m.\u001b[39mdeclared_html_encoding,\n\u001b[1;32m    389\u001b[0m        dammit\u001b[39m.\u001b[39mcontains_replacement_characters)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/dammit.py:601\u001b[0m, in \u001b[0;36mUnicodeDammit.__init__\u001b[0;34m(self, markup, known_definite_encodings, smart_quotes_to, is_html, exclude_encodings, user_encodings, override_encodings)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmarkup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mmarkup\n\u001b[1;32m    600\u001b[0m u \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m \u001b[39mfor\u001b[39;00m encoding \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mencodings:\n\u001b[1;32m    602\u001b[0m     markup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetector\u001b[39m.\u001b[39mmarkup\n\u001b[1;32m    603\u001b[0m     u \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_from(encoding)\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/dammit.py:442\u001b[0m, in \u001b[0;36mEncodingDetector.encodings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m# Use third-party character set detection to guess at the\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m# encoding.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchardet_encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchardet_encoding \u001b[39m=\u001b[39m chardet_dammit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmarkup)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_usable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchardet_encoding, tried):\n\u001b[1;32m    444\u001b[0m     \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchardet_encoding\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/bs4/dammit.py:46\u001b[0m, in \u001b[0;36mchardet_dammit\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(s, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m chardet_module\u001b[39m.\u001b[39;49mdetect(s)[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/charset_normalizer/legacy.py:28\u001b[0m, in \u001b[0;36mdetect\u001b[0;34m(byte_str)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(byte_str, \u001b[39mbytearray\u001b[39m):\n\u001b[1;32m     26\u001b[0m     byte_str \u001b[39m=\u001b[39m \u001b[39mbytes\u001b[39m(byte_str)\n\u001b[0;32m---> 28\u001b[0m r \u001b[39m=\u001b[39m from_bytes(byte_str)\u001b[39m.\u001b[39mbest()\n\u001b[1;32m     30\u001b[0m encoding \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mencoding \u001b[39mif\u001b[39;00m r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     31\u001b[0m language \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mlanguage \u001b[39mif\u001b[39;00m r \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m r\u001b[39m.\u001b[39mlanguage \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mUnknown\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/charset_normalizer/api.py:300\u001b[0m, in \u001b[0;36mfrom_bytes\u001b[0;34m(sequences, steps, chunk_size, threshold, cp_isolation, cp_exclusion, preemptive_behaviour, explain)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m cut_sequence_chunks(\n\u001b[1;32m    288\u001b[0m     sequences,\n\u001b[1;32m    289\u001b[0m     encoding_iana,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m     decoded_payload,\n\u001b[1;32m    297\u001b[0m ):\n\u001b[1;32m    298\u001b[0m     md_chunks\u001b[39m.\u001b[39mappend(chunk)\n\u001b[0;32m--> 300\u001b[0m     md_ratios\u001b[39m.\u001b[39mappend(mess_ratio(chunk, threshold))\n\u001b[1;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m md_ratios[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold:\n\u001b[1;32m    303\u001b[0m         early_stop_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/charset_normalizer/md.py:538\u001b[0m, in \u001b[0;36mmess_ratio\u001b[0;34m(decoded_sequence, maximum_threshold, debug)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[39mfor\u001b[39;00m character, index \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(decoded_sequence \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39mrange\u001b[39m(length)):\n\u001b[1;32m    537\u001b[0m     \u001b[39mfor\u001b[39;00m detector \u001b[39min\u001b[39;00m detectors:\n\u001b[0;32m--> 538\u001b[0m         \u001b[39mif\u001b[39;00m detector\u001b[39m.\u001b[39;49meligible(character):\n\u001b[1;32m    539\u001b[0m             detector\u001b[39m.\u001b[39mfeed(character)\n\u001b[1;32m    541\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    542\u001b[0m         index \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m index \u001b[39m%\u001b[39m intermediary_mean_mess_ratio_calc \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    543\u001b[0m     ) \u001b[39mor\u001b[39;00m index \u001b[39m==\u001b[39m length \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n","File \u001b[0;32m~/.pyenv/versions/3.9.6/lib/python3.9/site-packages/charset_normalizer/md.py:380\u001b[0m, in \u001b[0;36mArchaicUpperLowerPlugin.eligible\u001b[0;34m(self, character)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_alpha_seen: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    378\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_ascii_only: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meligible\u001b[39m(\u001b[39mself\u001b[39m, character: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfeed\u001b[39m(\u001b[39mself\u001b[39m, character: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["df_meta = getArticles(\"https://www.investing.com/equities/facebook-inc-news/\",20,1211) "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df_tsla.to_csv('../Data/Stock/tsla_news.csv',index=False)\n","df_aapl.to_csv('../Data/Stock/aapl_news.csv',index=False)\n","df_meta.to_csv('../Data/Stock/meta_news.csv',index=False)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMd/bJlxHgM7Jk6FKAtAJxs","collapsed_sections":[],"name":"","version":""},"kernelspec":{"display_name":"Python 3.9.6 64-bit ('3.9.6')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"vscode":{"interpreter":{"hash":"b6d02d92f30c3afccc504c0af6ec862fbbb99c882594c9ef1e8923a1750355a8"}}},"nbformat":4,"nbformat_minor":0}
